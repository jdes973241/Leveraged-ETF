import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import altair as alt
from arch import arch_model
from collections import defaultdict
from datetime import datetime, timedelta
import warnings

# ==========================================
# 0. é é¢è¨­å®šèˆ‡åƒæ•¸
# ==========================================
st.set_page_config(page_title="Dynamic Momentum Strategy (Final Audited)", layout="wide")
warnings.simplefilter(action='ignore')

# CSS ç¾åŒ–
st.markdown("""
<style>
    .metric-card {
        background-color: #eef2f5; 
        padding: 15px; 
        border-radius: 8px; 
        border: 1px solid #d1d5db;
        text-align: center;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .metric-label {font-size: 14px; color: #555555; margin-bottom: 0; font-weight: 500;}
    .metric-value {font-size: 24px; font-weight: bold; color: #000000 !important; margin: 5px 0;}
    .metric-sub {font-size: 12px; color: #666666; margin-bottom: 0;}
    .buy-text {color: #28a745; font-weight: bold;}
    .sell-text {color: #dc3545; font-weight: bold;}
</style>
""", unsafe_allow_html=True)

# === æ ¸å¿ƒåƒæ•¸ ===
MAPPING = {"UPRO": "SPY", "EURL": "VGK", "EDC": "EEM"} 
SAFE_POOL = ["GLD", "TLT"] 

# [ä¿®æ­£ 2] çµ±ä¸€åƒæ•¸ç‚º Q80 / Q65
RISK_CONFIG = {
    "UPRO": {"exit_q": 0.80, "entry_q": 0.65},
    "EURL": {"exit_q": 0.80, "entry_q": 0.65},
    "EDC":  {"exit_q": 0.80, "entry_q": 0.65}
}

ROLLING_WINDOW_SIZE = 1260 
SMA_WINDOW = 200
MOM_PERIODS = [3, 6, 9, 12]
TRANSACTION_COST = 0.001 
RF_RATE = 0.04 

# === åˆæˆæ•¸æ“šåƒæ•¸ ===
LEVERAGE_RATIO = 3.0
def get_daily_leverage_cost(date):
    year = date.year
    if year <= 2007 or year >= 2022: return 0.05 / 252 
    else: return 0.02 / 252

# ==========================================
# 1. æ ¸å¿ƒé‚è¼¯å‡½æ•¸ (Live Dashboard)
# ==========================================

@st.cache_data(ttl=3600, show_spinner="æ­£åœ¨ä¸‹è¼‰å¸‚å ´æ•¸æ“š...")
def get_market_data():
    tickers = list(MAPPING.keys()) + list(MAPPING.values()) + SAFE_POOL
    try:
        data = yf.download(tickers, period="max", interval="1d", auto_adjust=True, progress=False)
        if isinstance(data.columns, pd.MultiIndex):
            if 'Close' in data.columns.levels[0]: data = data['Close']
            else: data = data['Close'] if 'Close' in data else data
        
        start_filter = pd.Timestamp("2010-01-01")
        return data.loc[start_filter:].ffill().dropna()
    except Exception as e:
        st.error(f"æ•¸æ“šä¸‹è¼‰å¤±æ•—: {e}")
        return pd.DataFrame()

@st.cache_data(ttl=3600, show_spinner="æ­£åœ¨è¨ˆç®— GARCH é¢¨æ§æ¨¡å‹...")
def calculate_risk_metrics(data):
    if data.empty: return {}
    risk_details = {}
    
    for trade_t, signal_t in MAPPING.items():
        if signal_t not in data.columns: continue

        series = data[signal_t]
        ret = series.pct_change() * 100
        sma = series.rolling(SMA_WINDOW).mean()
        
        window = ret.dropna().tail(1260*2) 
        if len(window) < 100: continue

        try:
            am = arch_model(window, vol='Garch', p=1, q=1, dist='t', rescale=False)
            res = am.fit(disp='off', show_warning=False)
            cond_vol = res.conditional_volatility * np.sqrt(252)
            
            df = pd.DataFrame({'Price': series, 'Ret': ret, 'SMA': sma})
            df['Vol'] = cond_vol
            df = df.dropna()

            cfg = RISK_CONFIG[trade_t]
            # [ä¿®æ­£ 1] é¿å…æœªä¾†è¦–è§’: ä½¿ç”¨ shift(1)
            # ä»Šå¤©çš„é–¾å€¼æ˜¯ç”±æ˜¨å¤©æ”¶ç›¤ç®—å‡ºçš„åˆ†å¸ƒæ±ºå®šçš„
            df['Exit_Th'] = df['Vol'].rolling(252).quantile(cfg['exit_q']).shift(1)
            df['Entry_Th'] = df['Vol'].rolling(252).quantile(cfg['entry_q']).shift(1)
            
            df['GARCH_State'] = np.nan
            valid = df['Exit_Th'].notna()
            # è¨Šè™Ÿåˆ¤æ–·: 
            # è‹¥ä»Šæ—¥Vol > ä»Šæ—¥é–¾å€¼(æ˜¨å¤©ç®—çš„)ï¼Œå‰‡è½‰ç‚ºé¿éšª
            # é€™è£¡é‚è¼¯æ˜¯: ç›¤ä¸­è‹¥æ³¢å‹•ç‡é£†å‡è¶…éè­¦æˆ’ç·šï¼Œæ”¶ç›¤ç¢ºèªå¾Œï¼Œæ˜æ—¥åŸ·è¡Œé¿éšª
            df.loc[valid & (df['Vol'] > df['Exit_Th']), 'GARCH_State'] = 0.0 
            df.loc[valid & (df['Vol'] < df['Entry_Th']), 'GARCH_State'] = 1.0 
            df['GARCH_State'] = df['GARCH_State'].ffill().fillna(1.0)
            
            df['SMA_State'] = (df['Price'] > df['SMA']).astype(float)
            df['Weight'] = (0.5 * df['GARCH_State']) + (0.5 * df['SMA_State'])
            
            risk_details[trade_t] = df
        except: continue
        
    return risk_details

@st.cache_data(ttl=3600)
def calculate_selection_metrics(data):
    if data.empty: return pd.DataFrame()
    prices = data[list(MAPPING.keys())]
    metrics = []
    
    for ticker in prices.columns:
        row = {'Ticker': ticker}
        p_now = prices[ticker].iloc[-1]
        for m in MOM_PERIODS:
            lookback = m * 21
            if len(prices) > lookback:
                p_prev = prices[ticker].iloc[-1-lookback]
                ret = (p_now - p_prev) / p_prev
                row[f'Ret_{m}M'] = ret
            else: row[f'Ret_{m}M'] = np.nan
        
        vol_window = 126
        daily_ret = prices[ticker].pct_change().tail(vol_window)
        vol = daily_ret.std() * np.sqrt(252)
        row['Vol_Ann'] = vol
        metrics.append(row)
        
    df = pd.DataFrame(metrics).set_index('Ticker')
    z_score_sum = pd.Series(0.0, index=df.index)
    for m in MOM_PERIODS:
        col = f'Ret_{m}M'
        risk_adj = df[col] / (df['Vol_Ann'] + 1e-6)
        z = (risk_adj - risk_adj.mean()) / (risk_adj.std() + 1e-6)
        df[f'Z_{m}M'] = z
        z_score_sum += z
    df['Total_Z'] = z_score_sum
    df['Rank'] = df['Total_Z'].rank(ascending=False)
    return df.sort_values('Total_Z', ascending=False)

@st.cache_data(ttl=3600)
def get_safe_asset_status(data):
    """
    [ä¿®æ­£ 3] æ¯æœˆèª¿æ•´ä¸€æ¬¡ GLD/TLT
    é‚è¼¯ï¼šæ¯”è¼ƒä¸Šå€‹æœˆåº• (Monthly Resample) çš„ 12M å ±é…¬
    """
    if data.empty: return "TLT", {}
    
    # å–æœˆåº¦æ•¸æ“š
    monthly = data[SAFE_POOL].resample('M').last()
    
    # ç¢ºä¿æœ‰è¶³å¤ æ­·å²
    if len(monthly) > 12:
        # æ¯”è¼ƒä¸Šå€‹æœˆåº•çš„æ•¸æ“š (iloc[-1] æ˜¯æœ¬æœˆé‚„æ²’èµ°å®Œçš„ï¼Œiloc[-2] æ˜¯ä¸Šå€‹æœˆåº•)
        # å¯¦éš›ä¸Š Live Dashboard æ‡‰è©²çœ‹ã€Œæœ€æ–°å·²å®Œæˆçš„æœˆä»½ã€æˆ–ã€Œç•¶ä¸‹å³æ™‚ç‹€æ…‹ã€
        # ç‚ºäº†ç¬¦åˆã€Œæ¯æœˆèª¿æ•´ä¸€æ¬¡ã€çš„é‚è¼¯ï¼Œæˆ‘å€‘åªå–æœ€è¿‘ä¸€å€‹ã€Œæœˆåº•ã€çš„è¨Šè™Ÿ
        
        # é€™è£¡æˆ‘å€‘å– monthly çš„æœ€å¾Œä¸€ç­† (å³æœ€æ–°æ•¸æ“šï¼Œå¯èƒ½æ˜¯æœˆä¸­ä¹Ÿå¯èƒ½æ˜¯æœˆåº•)
        # ä½†ç‚ºäº†åš´è¬¹ï¼Œå›æ¸¬é‚è¼¯æ˜¯æœˆåˆçœ‹ä¸Šå€‹æœˆåº•ã€‚Dashboard é¡¯ç¤º "ç•¶å‰ç‹€æ…‹"
        p_now = monthly.iloc[-1]
        p_prev = monthly.iloc[-13] # 12å€‹æœˆå‰
        ret_12m = (p_now / p_prev) - 1
    else:
        ret_12m = pd.Series(0.0, index=SAFE_POOL)
    
    winner = ret_12m.idxmax()
    
    details = pd.DataFrame({
        "Ticker": SAFE_POOL, 
        "12M Return": ret_12m.values
    }).set_index("Ticker")
    
    return winner, details

# ==========================================
# 2. å›æ¸¬å°ˆç”¨é‚è¼¯ (åˆæˆæ•¸æ“š + é•·å›æ¸¬)
# ==========================================

@st.cache_data(ttl=3600, show_spinner="ç”Ÿæˆé•·æ­·å²åˆæˆæ•¸æ“šä¸­ (2005~)...")
def get_synthetic_backtest_data():
    tickers = list(MAPPING.values()) + SAFE_POOL + ['VT']
    try:
        data_raw = yf.download(tickers, period="max", interval="1d", auto_adjust=True, progress=False)
        if isinstance(data_raw.columns, pd.MultiIndex):
            if 'Close' in data_raw.columns.levels[0]: data_raw = data_raw['Close']
            else: data_raw = data_raw['Close'] if 'Close' in data_raw else data_raw
        
        data_raw = data_raw.ffill().dropna(subset=['VGK', 'EEM', 'SPY', 'GLD', 'TLT'])
        
        synthetic_data = pd.DataFrame(index=data_raw.index)
        for t in SAFE_POOL + ['VT']:
            if t in data_raw.columns: synthetic_data[t] = data_raw[t]
            
        REVERSE_MAP = {v: k for k, v in MAPPING.items()} 
        for ticker_1x in MAPPING.values():
            ticker_3x = REVERSE_MAP[ticker_1x]
            ret_1x = data_raw[ticker_1x].pct_change().fillna(0)
            costs = pd.Series([get_daily_leverage_cost(d) for d in ret_1x.index], index=ret_1x.index)
            ret_3x = (ret_1x * 3.0) - costs
            syn_price = (1 + ret_3x).cumprod() * 100
            synthetic_data[ticker_3x] = syn_price
            synthetic_data[f"RAW_{ticker_3x}"] = data_raw[ticker_1x] 
            
        return synthetic_data
    except Exception as e:
        return pd.DataFrame()

# ==========================================
# 3. æ‡‰ç”¨ç¨‹å¼ä¸»é‚è¼¯
# ==========================================

data = get_market_data()

if data.empty:
    st.error("âŒ ç„¡æ³•ä¸‹è¼‰æ•¸æ“šï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
    st.stop()

risk_data = calculate_risk_metrics(data)
selection_df = calculate_selection_metrics(data)
safe_winner, safe_details_df = get_safe_asset_status(data)

latest_date = data.index[-1]
winner_ticker = selection_df.index[0] 

if winner_ticker not in risk_data:
    st.error(f"âŒ ç¼ºå°‘ {winner_ticker} çš„é¢¨æ§æ•¸æ“šã€‚")
    st.stop()

winner_risk_df = risk_data[winner_ticker]
latest_risk_row = winner_risk_df.iloc[-1]
final_weight = latest_risk_row['Weight']

# ==========================================
# 4. Dashboard å‰ç«¯é¡¯ç¤º
# ==========================================

st.title("ğŸ›¡ï¸ é›™é‡å‹•èƒ½èˆ‡å‹•æ…‹é¢¨æ§ç­–ç•¥")
st.caption(f"æ•¸æ“šåŸºæº–æ—¥: {latest_date.strftime('%Y-%m-%d')}")

# ç™½çš®æ›¸å€å¡Š
with st.expander("ğŸ“– ç­–ç•¥ç™½çš®æ›¸ (Strategy Whitepaper)", expanded=False):
    st.markdown("""
    ### ç­–ç•¥é‚è¼¯æ‘˜è¦
    æœ¬ç­–ç•¥æ¡ç”¨ **è¨Šè™Ÿèˆ‡åŸ·è¡Œåˆ†é›¢ (Decoupled Signal)** æ¶æ§‹ï¼Œåˆ©ç”¨ 1x åŸå‹é æ¸¬é¢¨éšªï¼Œæ“ä½œ 3x æ§“æ¡¿ç²åˆ©ã€‚
    
    #### 1. é¸è‚¡å¼•æ“ (Selection Engine)
    * **å°è±¡**: UPRO, EURL, EDC (3x æ§“æ¡¿)ã€‚
    * **é‚è¼¯**: è¨ˆç®— 3M, 6M, 9M, 12M çš„ **é¢¨éšªèª¿æ•´å¾Œå ±é…¬**ï¼Œä¸¦é€²è¡Œ **Z-Score** æ’åºã€‚
    * **æ±ºç­–**: é¸å‡ºç¸½åˆ†æœ€é«˜çš„æ¨™çš„ä½œç‚ºæœ¬æœˆ Winnerã€‚
    
    #### 2. é¢¨æ§å¼•æ“ (Risk Engine)
    * **å°è±¡**: SPY, VGK, EEM (1x åŸå‹)ã€‚
    * **A è»Œ (GARCH)**: æ¯æ—¥æ»¾å‹•é æ¸¬æ³¢å‹•ç‡ã€‚è‹¥ `Vol > Exit(Q80)` é¿éšªï¼›è‹¥ `Vol < Entry(Q65)` æŒæœ‰ã€‚
    * **B è»Œ (SMA)**: è‹¥åƒ¹æ ¼ > 200MA æŒæœ‰ï¼›å¦å‰‡é¿éšªã€‚
    * **æ¬Šé‡**: 0.5 * GARCH + 0.5 * SMAã€‚
    
    #### 3. é¿éšªè¼ªå‹• (Safe Asset Rotation)
    * ç•¶é¢¨æ§å»ºè­°ç©ºå€‰æ™‚ï¼ŒæŒæœ‰ **GLD** æˆ– **TLT**ã€‚
    * **è¦å‰‡**: **æ¯æœˆåˆ** æ¯”è¼ƒå…©è€…éå» 12 å€‹æœˆç¸¾æ•ˆï¼ŒæŒæœ‰è¼ƒå¼·è€…ã€‚
    """)

# Summary Metrics
c1, c2, c3, c4 = st.columns(4)
with c1: st.metric("ğŸ† æœ¬æœˆé€²æ”»è´å®¶", winner_ticker, "Rank #1")
with c2:
    if final_weight == 1.0: st.markdown(f"### ğŸ¯ æ¬Šé‡: :green[100%]")
    elif final_weight == 0.5: st.markdown(f"### ğŸ¯ æ¬Šé‡: :orange[50%]")
    else: st.markdown(f"### ğŸ¯ æ¬Šé‡: :red[0%]")
with c3:
    g_state = latest_risk_row['GARCH_State']
    st.metric("æ³¢å‹•ç‡é¢¨æ§ (GARCH)", "å®‰å…¨" if g_state == 1.0 else "å±éšª", delta="âœ…" if g_state == 1.0 else "ğŸ”»")
with c4:
    safe_ret = safe_details_df.loc[safe_winner, '12M Return']
    st.metric("ğŸ›¡ï¸ ç•¶å‰æœ€ä½³é¿éšª", safe_winner, f"12M Ret: {safe_ret:.1%}")

st.divider()

# Strategy Tabs
st.subheader("ğŸ“Š ç­–ç•¥é€è¦–")
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["1ï¸âƒ£ æ•¸æ“šå±¤", "2ï¸âƒ£ é¢¨æ§å±¤", "3ï¸âƒ£ æ¬Šé‡å±¤", "4ï¸âƒ£ é¸è‚¡å±¤", "5ï¸âƒ£ é¿éšªè³‡ç”¢å±¤", "6ï¸âƒ£ åŸ·è¡Œå±¤"])

with tab1:
    st.caption("æœ€æ–°å¸‚å ´åƒ¹æ ¼ (å« 1x åŸå‹)")
    cols = list(MAPPING.keys()) + list(MAPPING.values()) + SAFE_POOL
    st.dataframe(data[cols].tail(5).sort_index(ascending=False).style.format("{:.2f}"), use_container_width=True)

with tab2:
    st.caption("é¢¨æ§æŒ‡æ¨™è©³æƒ… (Q80 Exit / Q65 Entry)")
    risk_summary = []
    for ticker, signal_t in MAPPING.items():
        if ticker in risk_data:
            row = risk_data[ticker].iloc[-1]
            risk_summary.append({
                "æ¨™çš„": ticker, "Vol": f"{row['Vol']:.2f}%", 
                "Exit(Q80)": f"{row['Exit_Th']:.2f}%", "Entry(Q65)": f"{row['Entry_Th']:.2f}%",
                "GARCH": "ğŸŸ¢" if row['GARCH_State']==1 else "ğŸ”´",
                "SMA": "ğŸŸ¢" if row['SMA_State']==1 else "ğŸ”´"
            })
    st.dataframe(pd.DataFrame(risk_summary), use_container_width=True)

with tab3:
    st.caption("æ¬Šé‡è¨ˆç®—ï¼š0.5*GARCH + 0.5*SMA")
    w_summary = []
    for ticker in MAPPING.keys():
        if ticker in risk_data:
            row = risk_data[ticker].iloc[-1]
            w_summary.append({
                "æ¨™çš„": ticker, "GARCH(0/1)": int(row['GARCH_State']), "SMA(0/1)": int(row['SMA_State']), "ç¸½æ¬Šé‡": row['Weight']
            })
    st.dataframe(pd.DataFrame(w_summary), use_container_width=True)

with tab4:
    st.caption("å‹•èƒ½æ’å (Risk-Adjusted Z-Score)")
    st.dataframe(selection_df.style.format("{:.2f}"), use_container_width=True)

with tab5:
    st.caption("é¿éšªè³‡ç”¢è¼ªå‹• (Safe Asset Rotation)")
    safe_display = safe_details_df.copy()
    safe_display['Selected'] = safe_display.index.map(lambda x: 'âœ…' if x == safe_winner else '')
    st.dataframe(safe_display.style.format({"12M Return": "{:.2%}"}).map(lambda x: 'color: green' if x == 'âœ…' else '', subset=['Selected']), use_container_width=True)

with tab6:
    st.markdown("#### ğŸš€ æœ€çµ‚åŸ·è¡ŒæŒ‡ä»¤")
    holdings = []
    if final_weight > 0: holdings.append(f"**{final_weight*100:.0f}% {winner_ticker}** (é€²æ”»)")
    safe_weight = 1.0 - final_weight
    if safe_weight > 0: holdings.append(f"**{safe_weight*100:.0f}% {safe_winner}** (é¿éšª)")
    st.success(f"å»ºè­°çµ„åˆ: {' + '.join(holdings)}")

# ==========================================
# 5. æ­·å²å›æ¸¬åˆ†æ (Synthetic Backtest)
# ==========================================
st.markdown("---")
st.header("â³ æ­·å²å›æ¸¬åˆ†æ (Synthetic)")

syn_data = get_synthetic_backtest_data()

if syn_data.empty:
    st.warning("åˆæˆæ•¸æ“šç”Ÿæˆå¤±æ•—ã€‚")
else:
    BACKTEST_GARCH_WINDOW = 504 
    est_start_date = syn_data.index[0] + timedelta(days=(BACKTEST_GARCH_WINDOW + 252) * 1.45) 
    start_date_str = est_start_date.strftime('%Y-%m-%d')

    st.caption(f"""
    **å›æ¸¬è¨­å®šèªªæ˜ï¼š**
    1.  **æ•¸æ“šæº**ï¼šä½¿ç”¨ 1x åŸå‹åˆæˆ 3x æ•¸æ“š (å«å‹•æ…‹æè€—)ã€‚
    2.  **å›æ¸¬èµ·é»**ï¼šç´„ {start_date_str} (ç¢ºä¿è¦†è“‹ 2008)ã€‚
    3.  **äº¤æ˜“æˆæœ¬**ï¼š0.1% | **GARCH æš–æ©Ÿ**ï¼š2 å¹´ (504å¤©)ã€‚
    4.  **é¿éšª**ï¼šGLD/TLT (æ¯æœˆåˆ‡æ›ä¸€æ¬¡)ã€‚
    5.  **åŸºæº– (Benchmark)**ï¼šUPRO + EURL + EDC (æ¯å­£ç­‰æ¬Šé‡)ã€‚
    """)

    if st.button("ğŸš€ é–‹å§‹åŸ·è¡Œå›æ¸¬ (Synthetic)"):
        with st.spinner("æ­£åœ¨é€²è¡Œæ­·å²é‹ç®—..."):
            # 1. è¨ˆç®—æ­·å²é¢¨æ§æ¬Šé‡
            h_risk_weights = pd.DataFrame(index=syn_data.index, columns=MAPPING.keys())
            
            for ticker_3x in MAPPING.keys():
                col_1x = f"RAW_{ticker_3x}"
                if col_1x not in syn_data.columns: continue
                s = syn_data[col_1x]
                r = s.pct_change() * 100
                sma = s.rolling(SMA_WINDOW).mean()
                
                win = r.dropna()
                am = arch_model(win, vol='Garch', p=1, q=1, dist='t', rescale=False)
                res = am.fit(disp='off', show_warning=False)
                vol = res.conditional_volatility * np.sqrt(252)
                
                df = pd.DataFrame({'Vol': vol, 'Price': s, 'SMA': sma})
                cfg = RISK_CONFIG[ticker_3x]
                
                # [ä¿®æ­£ 1] æ‡‰ç”¨ Shift(1) é¿å…æœªä¾†è¦–è§’
                roll_ex = df['Vol'].rolling(252).quantile(cfg['exit_q']).shift(1)
                roll_en = df['Vol'].rolling(252).quantile(cfg['entry_q']).shift(1)
                
                g_sig = pd.Series(np.nan, index=df.index)
                valid = roll_ex.notna()
                g_sig.loc[valid & (df['Vol'] > roll_ex)] = 0.0
                g_sig.loc[valid & (df['Vol'] < roll_en)] = 1.0
                g_sig = g_sig.ffill().fillna(0.0)
                
                s_sig = (df['Price'] > df['SMA']).astype(float)
                h_risk_weights[ticker_3x] = (0.5 * g_sig) + (0.5 * s_sig)
                
            h_risk_weights = h_risk_weights.dropna()
            
            # 2. æ­·å²å‹•èƒ½ (Selection) - æœˆé »
            monthly_prices = syn_data[list(MAPPING.keys())].resample('M').last()
            mom_score = pd.DataFrame(0.0, index=monthly_prices.index, columns=monthly_prices.columns)
            for m in MOM_PERIODS: mom_score += monthly_prices.pct_change(m)
            hist_winners = mom_score.idxmax(axis=1)
            
            # 3. æ­·å²é¿éšª (Rotation) - [ä¿®æ­£ 3] æœˆé »
            safe_monthly = syn_data[SAFE_POOL].resample('M').last()
            safe_mom = safe_monthly.pct_change(12) # 12å€‹æœˆ
            hist_safe = safe_mom.idxmax(axis=1).fillna('TLT')
            
            # 4. é€æ—¥å›æ¸¬
            dates = syn_data.index
            start_idx = BACKTEST_GARCH_WINDOW + 252 
            
            strategy_ret = []
            valid_dates = []
            hold_counts = defaultdict(float)
            prev_pos = {} 
            
            progress = st.progress(0)
            
            for i in range(start_idx, len(dates)):
                if i % 100 == 0: progress.progress((i - start_idx) / (len(dates)-start_idx))
                today = dates[i]
                
                # å–å¾—"æ˜¨å¤©"çš„æ—¥æœŸ (æˆ–ä¸Šæ¬¡è¨Šè™Ÿæ›´æ–°æ—¥)
                yesterday = dates[i-1]
                
                # [é—œéµä¿®æ­£] ä½¿ç”¨æ˜¨å¤©ä»¥å‰çš„æ•¸æ“šæ±ºå®šä»Šæ—¥æŒå€‰
                
                # A. æ±ºå®šé€²æ”»æ¨™çš„ (æ¯æœˆåˆæ›´æ–°)
                # æ‰¾åˆ° yesterday ä¹‹å‰æœ€è¿‘çš„ä¸€å€‹æœˆåº•
                past_wins = hist_winners[hist_winners.index <= yesterday]
                if past_wins.empty: continue
                target_risky = past_wins.iloc[-1]
                
                # B. æ±ºå®šé¿éšªæ¨™çš„ (æ¯æœˆåˆæ›´æ–°) [ä¿®æ­£ 3]
                past_safe = hist_safe[hist_safe.index <= yesterday]
                if past_safe.empty: target_safe = 'TLT'
                else: target_safe = past_safe.iloc[-1]
                
                # C. æ±ºå®šæ¬Šé‡ (æ¯æ—¥æ›´æ–°)
                if target_risky in h_risk_weights.columns and yesterday in h_risk_weights.index:
                    w_risk = h_risk_weights.loc[yesterday, target_risky]
                    if pd.isna(w_risk): w_risk = 0.0
                else: w_risk = 0.0
                w_safe = 1.0 - w_risk
                
                # D. æ§‹å»ºæŒå€‰
                curr_pos = {}
                if w_risk > 0: curr_pos[target_risky] = w_risk
                if w_safe > 0: curr_pos[target_safe] = w_safe
                
                # E. è¨ˆç®—æˆæœ¬
                cost = 0.0
                all_assets = set(list(prev_pos.keys()) + list(curr_pos.keys()))
                for asset in all_assets:
                    w_prev = prev_pos.get(asset, 0.0)
                    w_curr = curr_pos.get(asset, 0.0)
                    if w_prev != w_curr:
                        cost += abs(w_curr - w_prev) * TRANSACTION_COST
                
                # F. è¨ˆç®—æç›Š (ä»Šæ—¥æ¼²è·Œ)
                day_ret = 0.0
                if w_risk > 0:
                    r = syn_data[target_risky].pct_change().iloc[i]
                    if np.isnan(r): r=0
                    day_ret += w_risk * r
                if w_safe > 0:
                    r = syn_data[target_safe].pct_change().iloc[i]
                    if np.isnan(r): r=0
                    day_ret += w_safe * r
                    
                strategy_ret.append(day_ret - cost)
                valid_dates.append(today)
                hold_counts[target_risky] += w_risk
                hold_counts[target_safe] += w_safe
                prev_pos = curr_pos
                
            progress.empty()
            
            # --- Result ---
            eq = pd.Series(strategy_ret, index=valid_dates)
            cum_eq = (1 + eq).cumprod()
            dd = cum_eq / cum_eq.cummax() - 1
            
            # Benchmark (Qtly EqW)
            b_subset = syn_data[list(MAPPING.keys())].loc[valid_dates].copy()
            b_equity_series = pd.Series(1.0, index=b_subset.index)
            curr_cap = 1.0
            q_ends = b_subset.groupby(pd.Grouper(freq='QE')).apply(lambda x: x.index[-1] if len(x)>0 else None).dropna()
            cps = sorted(list(set([b_subset.index[0]] + list(q_ends) + [b_subset.index[-1]])))
            
            for i in range(len(cps)-1):
                t_s = cps[i]
                t_e = cps[i+1]
                if t_s >= t_e: continue
                seg = b_subset.loc[t_s:t_e]
                if len(seg) < 2: continue
                rel = seg.div(seg.iloc[0])
                val = rel.mean(axis=1) * curr_cap
                b_equity_series.loc[t_s:t_e] = val
                curr_cap = val.iloc[-1]
            
            bench_eq = b_equity_series
            bench_dd = bench_eq / bench_eq.cummax() - 1
            
            # Benchmark 2 (VT)
            vt_eq = pd.Series(1.0, index=valid_dates)
            if 'VT' in syn_data.columns:
                vt_ret = syn_data['VT'].loc[valid_dates].pct_change().fillna(0)
                vt_eq = (1 + vt_ret).cumprod()
            vt_dd = vt_eq / vt_eq.cummax() - 1
            
            # Stats
            def calc_stats(equity, daily_r):
                if len(equity) < 1: return 0,0,0,0
                d = (equity.index[-1] - equity.index[0]).days
                y = d / 365.25
                cagr = (equity.iloc[-1] / equity.iloc[0]) ** (1/y) - 1
                mdd = (equity / equity.cummax() - 1).min()
                neg = daily_r[daily_r < 0]
                sortino = (cagr - RF_RATE) / (neg.std() * np.sqrt(252) + 1e-6)
                roll5 = equity.rolling(1260).apply(lambda x: (x.iloc[-1]/x.iloc[0])**(252/1260) - 1).mean()
                return cagr, sortino, roll5, mdd

            s_cagr, s_sort, s_roll, s_mdd = calc_stats(cum_eq, eq)
            b3_cagr, b3_sort, b3_roll, b3_mdd = calc_stats(bench_eq, bench_eq.pct_change().fillna(0))
            vt_cagr, vt_sort, vt_roll, vt_mdd = calc_stats(vt_eq, vt_eq.pct_change().fillna(0))
            
            total_d = len(valid_dates)
            time_in_mkt = (hold_counts['UPRO'] + hold_counts['EURL'] + hold_counts['EDC']) / total_d
            
            alloc_str = " | ".join([f"{k.replace('Syn_','')}:{v/total_d:.0%}" for k, v in hold_counts.items() if v/total_d > 0.01])
            
            # --- Display ---
            st.write("### ğŸ“ˆ å›æ¸¬ç¸¾æ•ˆæŒ‡æ¨™")
            m1, m2, m3, m4, m5 = st.columns(5)
            
            def metric_box(label, value, b3_val=None, vt_val=None, fmt="{:.2%}"):
                b3_str = f"3x: {fmt.format(b3_val)}" if b3_val is not None else ""
                vt_str = f"VT: {fmt.format(vt_val)}" if vt_val is not None else ""
                st.markdown(f"""
                <div class="metric-card">
                    <p class="metric-label">{label}</p>
                    <p class="metric-value">{fmt.format(value)}</p>
                    <p class="metric-sub">{b3_str} | {vt_str}</p>
                </div>
                """, unsafe_allow_html=True)

            with m1: metric_box("CAGR", s_cagr, b3_cagr, vt_cagr)
            with m2: metric_box("Sortino", s_sort, b3_sort, vt_sort, "{:.2f}")
            with m3: metric_box("Avg 5Y Roll", s_roll, b3_roll, vt_roll)
            with m4: metric_box("Max DD", s_mdd, b3_mdd, vt_mdd)
            with m5: metric_box("Time in 3x", time_in_mkt, None, None) 
            
            st.markdown(f"**å¹³å‡è³‡ç”¢åˆ†ä½ˆ:** {alloc_str}")
            
            # Charts
            st.write("### ğŸ“Š æ¬Šç›Šæ›²ç·šèˆ‡å›æ’¤")
            
            df_chart = pd.DataFrame({
                'Date': cum_eq.index,
                'Strategy': cum_eq,
                'Bench (3x EqW)': bench_eq,
                'Bench (VT)': vt_eq
            }).melt('Date', var_name='Asset', value_name='NAV')
            
            chart = alt.Chart(df_chart).mark_line().encode(
                x='Date',
                y=alt.Y('NAV', axis=alt.Axis(title='NAV (Log)'), scale=alt.Scale(type='log')),
                color=alt.Color('Asset', scale=alt.Scale(domain=['Strategy', 'Bench (3x EqW)', 'Bench (VT)'], range=['#1f77b4', '#999999', '#2ca02c'])),
                tooltip=['Date', 'Asset', alt.Tooltip('NAV', format='.2f')]
            ).properties(height=350, title="æ¬Šç›Šæ›²ç·š (Log Scale)").interactive()
            st.altair_chart(chart, use_container_width=True)
            
            df_dd = pd.DataFrame({
                'Date': cum_eq.index,
                'Strategy': dd,
                'Bench (3x EqW)': bench_dd,
                'Bench (VT)': vt_dd
            }).melt('Date', var_name='Asset', value_name='Drawdown')
            
            chart_dd = alt.Chart(df_dd).mark_line().encode(
                x='Date', y=alt.Y('Drawdown', axis=alt.Axis(format='%')),
                color='Asset', tooltip=['Date', 'Asset', alt.Tooltip('Drawdown', format='.2%')]
            ).properties(height=200, title="å›æ’¤å¹…åº¦").interactive()
            st.altair_chart(chart_dd, use_container_width=True)
            
            roll5_s = cum_eq.rolling(1260).apply(lambda x: (x.iloc[-1]/x.iloc[0])**(252/1260) - 1)
            roll5_b = bench_eq.rolling(1260).apply(lambda x: (x.iloc[-1]/x.iloc[0])**(252/1260) - 1)
            roll5_v = vt_eq.rolling(1260).apply(lambda x: (x.iloc[-1]/x.iloc[0])**(252/1260) - 1)
            
            df_roll = pd.DataFrame({
                'Date': cum_eq.index, 'Strategy': roll5_s, 'Bench (3x)': roll5_b, 'Bench (VT)': roll5_v
            }).melt('Date', var_name='Asset', value_name='CAGR')
            
            chart_roll = alt.Chart(df_roll.dropna()).mark_line().encode(
                x='Date', y=alt.Y('CAGR', axis=alt.Axis(format='%')),
                color='Asset', tooltip=['Date', 'Asset', alt.Tooltip('CAGR', format='.2%')]
            ).properties(height=250, title="æ»¾å‹• 5 å¹´å¹´åŒ–å ±é…¬ç‡ (Rolling 5Y CAGR)").interactive()
            st.altair_chart(chart_roll, use_container_width=True)
