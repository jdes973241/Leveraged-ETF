import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import altair as alt
from arch import arch_model
from collections import defaultdict
from datetime import datetime, timedelta
import warnings

# ==========================================
# 0. é é¢è¨­å®š
# ==========================================
st.set_page_config(page_title="Dynamic Momentum Strategy (Aggressive)", layout="wide")
warnings.simplefilter(action='ignore')
alt.data_transformers.disable_max_rows()

# CSS å„ªåŒ–
st.markdown("""
<style>
    .metric-card {
        background-color: #f8f9fa; 
        padding: 15px; 
        border-radius: 8px; 
        border: 1px solid #dee2e6;
        text-align: center;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .metric-label {font-size: 14px; color: #6c757d; margin-bottom: 0; font-weight: 600;}
    .metric-value {font-size: 24px; font-weight: bold; color: #212529 !important; margin: 5px 0;}
    .metric-sub {font-size: 12px; color: #adb5bd; margin-bottom: 0;}
</style>
""", unsafe_allow_html=True)

# ==========================================
# 1. æ ¸å¿ƒåƒæ•¸
# ==========================================
MAPPING = {"UPRO": "SPY", "EURL": "VGK", "EDC": "EEM"} 
SAFE_POOL = ["GLD", "TLT"] 

# é¢¨æ§é–¾å€¼ (Exit 0.99 / Entry 0.90)
RISK_CONFIG = {
    "UPRO": {"exit_q": 0.99, "entry_q": 0.90},
    "EURL": {"exit_q": 0.99, "entry_q": 0.90},
    "EDC":  {"exit_q": 0.99, "entry_q": 0.90}
}

# ç­–ç•¥åƒæ•¸
SMA_MONTHS = 6               # æœˆå‡ç·š
LIVE_GARCH_WINDOW = 504      # Live GARCH çª—å£
BACKTEST_GARCH_WINDOW = 504  # å›æ¸¬ GARCH çª—å£
REFIT_STEP = 5               # æ»¾å‹•é‡è¨“é »ç‡
MOM_PERIODS = [3, 6, 9, 12]
TRANSACTION_COST = 0.001 
RF_RATE = 0.02 

def get_daily_leverage_cost(date):
    year = date.year
    if year <= 2007 or year >= 2022: return 0.05 / 252 
    else: return 0.02 / 252

def get_monthly_data(df):
    """é–å®šæ¯å€‹æœˆå¯¦éš›æœ€å¾Œäº¤æ˜“æ—¥"""
    if df.empty: return df
    if not isinstance(df.index, pd.DatetimeIndex):
        df.index = pd.to_datetime(df.index)
        
    period_idx = df.index.to_period('M')
    month_end_dates = df.index.to_series().groupby(period_idx).max()
    return df.loc[month_end_dates]

# ==========================================
# 2. Live é¢æ¿æ•¸æ“šèˆ‡é‚è¼¯
# ==========================================
@st.cache_data(ttl=3600)
def get_live_data():
    tickers = list(MAPPING.keys()) + list(MAPPING.values()) + SAFE_POOL
    try:
        data = yf.download(tickers, period="5y", interval="1d", auto_adjust=True, progress=False, group_by='column')
        
        if isinstance(data.columns, pd.MultiIndex):
            if 'Close' in data.columns.levels[0]:
                data = data['Close']
            else:
                pass

        if data.index.tz is not None:
            data.index = data.index.tz_localize(None)

        data = data.ffill()
        data = data.dropna(how='all')
        
        return data
    except Exception as e:
        st.error(f"æ•¸æ“šä¸‹è¼‰å¤±æ•—: {e}")
        return pd.DataFrame()

@st.cache_data(ttl=3600)
def calculate_live_risk(data):
    if data.empty: return {}
    
    avail_cols = [c for c in list(MAPPING.keys()) if c in data.columns]
    if not avail_cols: return {}
    
    monthly_prices = get_monthly_data(data[avail_cols])
    monthly_sma = monthly_prices.rolling(SMA_MONTHS).mean()
    monthly_sig = (monthly_prices > monthly_sma).astype(float)
    daily_sma_sig = monthly_sig.reindex(data.index).ffill()
    
    risk_details = {}
    for trade_t, signal_t in MAPPING.items():
        if signal_t not in data.columns: continue
        if trade_t not in data.columns: 
             series = data[signal_t] 
        else:
             series = data[trade_t]
             
        ret = data[signal_t].pct_change() * 100
        
        # Live GARCH
        window = ret.dropna().tail(LIVE_GARCH_WINDOW * 2) 
        if len(window) < 100: continue
        
        try:
            am = arch_model(window, vol='Garch', p=1, q=1, dist='t', rescale=False)
            res = am.fit(disp='off', show_warning=False)
            cond_vol = res.conditional_volatility * np.sqrt(252)
            
            df = pd.DataFrame({'Price': series, 'Ret': ret})
            df['Vol'] = pd.Series(cond_vol, index=window.index).reindex(df.index)
            
            if trade_t in daily_sma_sig.columns:
                df['SMA_State'] = daily_sma_sig[trade_t]
            else:
                if MAPPING[trade_t] in daily_sma_sig.columns: 
                    df['SMA_State'] = 1.0 
                else:
                    df['SMA_State'] = 0.0
            
            cfg = RISK_CONFIG[trade_t]
            df['Exit_Th'] = df['Vol'].rolling(252).quantile(cfg['exit_q']).shift(1)
            df['Entry_Th'] = df['Vol'].rolling(252).quantile(cfg['entry_q']).shift(1)
            
            df['GARCH_State'] = np.nan
            valid = df['Exit_Th'].notna() & df['Vol'].notna()
            
            mask_exit = valid & (df['Vol'] > df['Exit_Th'])
            mask_entry = valid & (df['Vol'] < df['Entry_Th'])
            
            df.loc[mask_exit, 'GARCH_State'] = 0.0 
            df.loc[mask_entry, 'GARCH_State'] = 1.0 
            df['GARCH_State'] = df['GARCH_State'].ffill().fillna(1.0)
            
            df['Weight'] = (0.5 * df['GARCH_State']) + (0.5 * df['SMA_State'])
            df = df.dropna(subset=['Weight'])
            risk_details[trade_t] = df
        except: continue
    return risk_details

@st.cache_data(ttl=3600)
def calculate_live_selection(data):
    if data.empty: return pd.DataFrame(), None
    
    avail_keys = [k for k in list(MAPPING.keys()) if k in data.columns]
    if not avail_keys: return pd.DataFrame(), None
    
    prices = data[avail_keys]
    monthly = get_monthly_data(prices)
    
    if monthly.empty: return pd.DataFrame(), None

    last_date = data.index[-1]
    current_period = last_date.to_period('M')
    prev_months = monthly[monthly.index.to_period('M') < current_period]
    if prev_months.empty: return pd.DataFrame(), None
    
    ref_date = prev_months.index[-1]
    metrics = []
    
    for ticker in prices.columns:
        row = {'Ticker': ticker}
        try:
            p_now = monthly.loc[ref_date, ticker]
            for m in MOM_PERIODS:
                if ref_date not in monthly.index: continue
                loc = monthly.index.get_loc(ref_date)
                
                if loc >= m:
                    p_prev = monthly.iloc[loc-m][ticker]
                    if pd.isna(p_prev) or p_prev == 0:
                        row[f'Ret_{m}M'] = np.nan
                    else:
                        row[f'Ret_{m}M'] = (p_now - p_prev) / p_prev
                else: row[f'Ret_{m}M'] = np.nan
            
            d_loc = data.index.get_indexer([ref_date], method='pad')[0]
            if d_loc >= 126:
                subset = prices[ticker].iloc[d_loc-126 : d_loc]
                row['Vol_Ann'] = subset.pct_change().std() * np.sqrt(252)
            else: row['Vol_Ann'] = np.nan
            metrics.append(row)
        except: continue
        
    if not metrics: return pd.DataFrame(), None
    
    df = pd.DataFrame(metrics).set_index('Ticker')
    z_sum = pd.Series(0.0, index=df.index)
    for m in MOM_PERIODS:
        col = f'Ret_{m}M'
        if col in df.columns:
            risk_adj = df[col] / (df['Vol_Ann'] + 1e-6)
            z = (risk_adj - risk_adj.mean()) / (risk_adj.std() + 1e-6)
            df[f'Z_{m}M'] = z
            z_sum += z.fillna(0)
    df['Total_Z'] = z_sum
    return df.sort_values('Total_Z', ascending=False), ref_date

@st.cache_data(ttl=3600)
def calculate_live_safe(data):
    if data.empty: return "TLT", pd.DataFrame(), None
    
    avail_safe = [t for t in SAFE_POOL if t in data.columns]
    if not avail_safe: return "TLT", pd.DataFrame(), None

    monthly = get_monthly_data(data[avail_safe])
    if monthly.empty: return "TLT", pd.DataFrame(), None

    last_date = data.index[-1]
    current_period = last_date.to_period('M')
    prev_months = monthly[monthly.index.to_period('M') < current_period]
    if prev_months.empty: return "TLT", pd.DataFrame(), None
    
    ref_date = prev_months.index[-1]
    loc = monthly.index.get_loc(ref_date)
    
    if loc >= 12:
        ret_12m = (monthly.iloc[loc] / monthly.iloc[loc-12]) - 1
    else: ret_12m = pd.Series(0.0, index=avail_safe)
    
    winner = ret_12m.idxmax()
    details = pd.DataFrame({"Ticker": avail_safe, "12M Return": ret_12m.values}).set_index("Ticker")
    return winner, details, ref_date

# ==========================================
# 3. å›æ¸¬é‚è¼¯ (Strict Rolling)
# ==========================================
@st.cache_data(ttl=3600, show_spinner="æº–å‚™å›æ¸¬æ•¸æ“š (åˆæˆä¸‰å€æ§“æ¡¿)...")
def get_synthetic_backtest_data():
    tickers = list(MAPPING.values()) + SAFE_POOL + ['VT']
    try:
        data_raw = yf.download(tickers, period="max", interval="1d", auto_adjust=True, progress=False)
        
        if isinstance(data_raw.columns, pd.MultiIndex):
            if 'Close' in data_raw.columns.levels[0]: data_raw = data_raw['Close']
            else: pass
        
        if data_raw.index.tz is not None:
            data_raw.index = data_raw.index.tz_localize(None)

        data_raw = data_raw.ffill()
        
        synthetic_data = pd.DataFrame(index=data_raw.index)
        if 'VT' in data_raw.columns: synthetic_data['VT'] = data_raw['VT']
        for t in SAFE_POOL: 
            if t in data_raw.columns: synthetic_data[t] = data_raw[t]
            
        REVERSE_MAP = {v: k for k, v in MAPPING.items()} 
        for ticker_1x in MAPPING.values():
            if ticker_1x not in data_raw.columns: continue
            
            ticker_3x = REVERSE_MAP[ticker_1x]
            ret_1x = data_raw[ticker_1x].pct_change().fillna(0)
            costs = pd.Series([get_daily_leverage_cost(d) for d in ret_1x.index], index=ret_1x.index)
            ret_3x = (ret_1x * 3.0) - costs
            synthetic_data[ticker_3x] = (1 + ret_3x).cumprod() * 100
            synthetic_data[f"RAW_{ticker_3x}"] = data_raw[ticker_1x] 
            
        return synthetic_data.dropna()
    except: return pd.DataFrame()

@st.cache_data(ttl=3600, show_spinner="è¨ˆç®—æ»¾å‹•å›æ¸¬è¨Šè™Ÿ (é€™éœ€è¦ç´„ 1 åˆ†é˜)...")
def calculate_backtest_signals_rolling(data):
    # 1. æœˆå‡ç·š (SMA 6 Months)
    raw_cols = [f"RAW_{k}" for k in MAPPING.keys() if f"RAW_{k}" in data.columns]
    if not raw_cols: return pd.DataFrame(), pd.Series(), pd.Series()

    monthly_prices = get_monthly_data(data[raw_cols])
    monthly_sma = monthly_prices.rolling(SMA_MONTHS).mean()
    monthly_sma_sig = (monthly_prices > monthly_sma).astype(float)
    daily_sma_sig = monthly_sma_sig.reindex(data.index).ffill().shift(1)
    daily_sma_sig.columns = [c.replace("RAW_", "") for c in raw_cols]

    # 2. æ»¾å‹• GARCH
    target_tickers = [k for k in MAPPING.keys() if f"RAW_{k}" in data.columns]
    h_risk_weights = pd.DataFrame(index=data.index, columns=target_tickers)
    
    for i, ticker_3x in enumerate(target_tickers):
        col_1x = f"RAW_{ticker_3x}"
        s_ret = data[col_1x].pct_change() * 100
        forecasts = {}
        model_res = None
        loop_start = BACKTEST_GARCH_WINDOW
        
        ret_values = s_ret.values
        dates = s_ret.index
        
        for t in range(loop_start, len(s_ret)):
            if (t - loop_start) % REFIT_STEP == 0 or model_res is None:
                train = s_ret.iloc[t-BACKTEST_GARCH_WINDOW : t]
                if train.std() < 1e-6: continue
                try:
                    am = arch_model(train, vol='Garch', p=1, q=1, dist='t', rescale=False)
                    model_res = am.fit(disp='off', show_warning=False)
                except: pass
            
            if model_res:
                try:
                    fc = model_res.forecast(horizon=1, reindex=False)
                    vol = np.sqrt(fc.variance.iloc[-1].values[0]) * np.sqrt(252)
                    forecasts[dates[t]] = vol
                except: pass
        
        vol_series = pd.Series(forecasts).reindex(data.index)
        cfg = RISK_CONFIG[ticker_3x]
        
        ex_th = vol_series.rolling(252).quantile(cfg['exit_q']).shift(1)
        en_th = vol_series.rolling(252).quantile(cfg['entry_q']).shift(1)
        
        g_sig = pd.Series(np.nan, index=data.index)
        valid = ex_th.notna()
        g_sig.loc[valid & (vol_series > ex_th)] = 0.0
        g_sig.loc[valid & (vol_series < en_th)] = 1.0
        g_sig = g_sig.ffill().fillna(0.0)
        
        if ticker_3x in daily_sma_sig.columns:
            s_sig = daily_sma_sig[ticker_3x]
            h_risk_weights[ticker_3x] = 0.5*g_sig + 0.5*s_sig
        
    h_risk_weights = h_risk_weights.dropna()
    
    # 3. é¸è‚¡ (Monthly)
    monthly_src = get_monthly_data(data[raw_cols])
    monthly_src.columns = [c.replace("RAW_", "") for c in raw_cols]
    
    daily_vol = data[raw_cols].pct_change().rolling(126).std() * np.sqrt(252)
    monthly_vol = get_monthly_data(daily_vol)
    monthly_vol.columns = monthly_src.columns
    
    scores = pd.DataFrame(0.0, index=monthly_src.index, columns=monthly_src.columns)
    for m in MOM_PERIODS:
        ret = monthly_src.pct_change(m)
        risk_adj = ret / (monthly_vol + 1e-6)
        z = risk_adj.sub(risk_adj.mean(axis=1), axis=0).div(risk_adj.std(axis=1)+1e-6, axis=0)
        scores += z.fillna(0)
    hist_winners = scores.idxmax(axis=1)
    
    # 4. é¿éšªè¼ªå‹•
    avail_safe = [t for t in SAFE_POOL if t in data.columns]
    safe_monthly = get_monthly_data(data[avail_safe])
    hist_safe = safe_monthly.pct_change(12).idxmax(axis=1).fillna('TLT')
    
    return h_risk_weights, hist_winners, hist_safe

def run_backtest_logic(data, risk_weights, winners_series, safe_signals):
    dates = data.index
    # èµ·å§‹é»: GARCHçª—å£(504) + Quantileçª—å£(252) = 756
    start_idx = BACKTEST_GARCH_WINDOW + 252
    
    # æª¢æŸ¥ VT ä¸Šå¸‚æ™‚é–“ï¼Œé¿å…å›æ¸¬æ—©æœŸ VT æ•¸æ“šç‚ºç©º
    vt_start = data['VT'].first_valid_index()
    if vt_start:
        vt_idx = data.index.get_loc(vt_start)
        # å–æœ€å¤§å€¼ï¼Œç¢ºä¿æ•¸æ“šèˆ‡æ¨¡å‹çš†å·²å‚™å¦¥
        start_idx = max(start_idx, vt_idx)
    
    if start_idx >= len(dates): return None, None, None, None
    
    strategy_ret = []
    valid_dates = []
    hold_counts = defaultdict(float)
    prev_pos = {}
    
    # Daily Loop
    for i in range(start_idx, len(dates)):
        today = dates[i]
        yesterday = dates[i-1]
        
        # Monthly Selection
        past_wins = winners_series[winners_series.index <= yesterday]
        if past_wins.empty: continue
        target_risky = past_wins.iloc[-1]
        
        past_safe = safe_signals[safe_signals.index <= yesterday]
        if past_safe.empty: target_safe = 'TLT'
        else: target_safe = past_safe.iloc[-1]
        
        # Weight
        if target_risky in risk_weights.columns and yesterday in risk_weights.index:
            w_risk = risk_weights.loc[yesterday, target_risky]
            if pd.isna(w_risk): w_risk = 0.0
        else: w_risk = 0.0
        w_safe = 1.0 - w_risk
        
        # Calc
        curr_pos = {}
        if w_risk > 0: curr_pos[target_risky] = w_risk
        if w_safe > 0: curr_pos[target_safe] = w_safe
        
        cost = 0.0
        all_assets = set(list(prev_pos.keys()) + list(curr_pos.keys()))
        for asset in all_assets:
            w_prev = prev_pos.get(asset, 0.0)
            w_curr = curr_pos.get(asset, 0.0)
            if w_prev != w_curr: cost += abs(w_curr - w_prev) * TRANSACTION_COST
            
        day_ret = 0.0
        if w_risk > 0:
            if target_risky in data.columns:
                r = data[target_risky].pct_change().iloc[i]
                if np.isnan(r): r=0
                day_ret += w_risk * r
        if w_safe > 0:
            if target_safe in data.columns:
                r = data[target_safe].pct_change().iloc[i]
                if np.isnan(r): r=0
                day_ret += w_safe * r
            
        strategy_ret.append(day_ret - cost)
        valid_dates.append(today)
        
        # è¨˜éŒ„æŒå€‰ä»¥è¨ˆç®— Time in 3x
        hold_counts[target_risky] += w_risk
        hold_counts[target_safe] += w_safe
        
        prev_pos = curr_pos
        
    eq = pd.Series(strategy_ret, index=valid_dates)
    cum_eq = (1 + eq).cumprod()
    
    # Benchmarks
    b_cols = [c for c in list(MAPPING.keys()) if c in data.columns]
    b_sub = data[b_cols].loc[valid_dates].copy()
    b_eq = pd.Series(1.0, index=b_sub.index)
    curr = 1.0
    q_ends = b_sub.groupby(pd.Grouper(freq='QE')).apply(lambda x: x.index[-1] if len(x)>0 else None).dropna()
    cps = sorted(list(set([b_sub.index[0]] + list(q_ends) + [b_sub.index[-1]])))
    for i in range(len(cps)-1):
        t_s, t_e = cps[i], cps[i+1]
        if t_s >= t_e: continue
        seg = b_sub.loc[t_s:t_e]
        if len(seg)<2: continue
        rel = seg.div(seg.iloc[0])
        val = rel.mean(axis=1) * curr
        b_eq.loc[t_s:t_e] = val
        curr = val.iloc[-1]
        
    vt_eq = (1 + data['VT'].loc[valid_dates].pct_change().fillna(0)).cumprod()
    
    return cum_eq, b_eq, vt_eq, hold_counts

# ==========================================
# 4. Dashboard ä»‹é¢
# ==========================================
st.title("ğŸ›¡ï¸ é›™é‡å‹•èƒ½èˆ‡å‹•æ…‹é¢¨æ§ (Live + Rolling Backtest)")
st.caption(f"é…ç½®: SMA {SMA_MONTHS}M (Monthly) / GARCH (Q{RISK_CONFIG['UPRO']['exit_q']*100:.0f}) / Safe (GLD/TLT)")

# --- Debug Panel (éš±è—å¼) ---
with st.expander("ğŸ› ï¸ æ•¸æ“šé™¤éŒ¯èˆ‡ç‹€æ…‹ (è‹¥æ•¸æ“šç‚º N/A è«‹é»æ­¤)"):
    live_data = get_live_data()
    st.write("åŸå§‹æ•¸æ“šå½¢ç‹€:", live_data.shape)
    st.write("åŒ…å«æ¬„ä½:", live_data.columns.tolist())
    st.write("æœ€å¾Œæ›´æ–°æ—¥æœŸ:", live_data.index[-1] if not live_data.empty else "ç„¡")
    if live_data.empty:
        st.error("âš ï¸ è­¦å‘Šï¼šç„¡æ³•ä¸‹è¼‰æ•¸æ“šï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šæˆ– Yahoo Finance ç‹€æ…‹ã€‚")
    else:
        st.success("âœ… æ•¸æ“šä¸‹è¼‰æ­£å¸¸")

# --- Live Data Loading ---
risk_live = calculate_live_risk(live_data)
sel_df, sel_date = calculate_live_selection(live_data)
safe_win, safe_df, safe_date = calculate_live_safe(live_data)

winner = sel_df.index[0] if not sel_df.empty else "N/A"
if winner in risk_live:
    latest_r = risk_live[winner].iloc[-1]
    final_w = latest_r['Weight']
    g_state = latest_r['GARCH_State']
else:
    final_w = 0.0
    g_state = 0.0

if sel_date:
    st.info(f"ğŸ”’ **è¨Šè™Ÿé–å®šæ—¥**: {sel_date.strftime('%Y-%m-%d')} (ä¸Šå€‹æœˆæœ€å¾Œäº¤æ˜“æ—¥)")

with st.expander("ğŸ“– ç­–ç•¥è©³ç´°è¦å‰‡", expanded=False):
    st.markdown(r"""
    é€™ä»½ç¨‹å¼ç¢¼å»ºæ§‹äº†ä¸€å€‹ **ã€Œé›™é‡å‹•èƒ½èˆ‡å‹•æ…‹é›™å±¤é¢¨æ§ï¼ˆDual Momentum with Dynamic Dual-Layer Risk Controlï¼‰ã€** çš„ç­–ç•¥å„€è¡¨æ¿ï¼Œä¸¦åŒ…å«å³æ™‚ç›£æ§ï¼ˆLiveï¼‰èˆ‡åš´æ ¼çš„æ»¾å‹•å›æ¸¬ï¼ˆStrict Rolling Backtestï¼‰å…©å¤§æ¨¡çµ„ã€‚
    
    ä»¥ä¸‹æ˜¯ä¾æ“šç¨‹å¼ç¢¼é‚è¼¯æ‹†è§£çš„å®Œæ•´ç­–ç•¥è¦æ ¼èˆ‡æ•¸æ“šç´°ç¯€ï¼š
    
    ### 1. æŠ•è³‡å…¨é›†èˆ‡è³‡ç”¢æ˜ å°„ (Asset Universe)
    ç­–ç•¥æ¡ç”¨ **æ§“æ¡¿ ETF** ä½œç‚ºé€²æ”»è³‡ç”¢ï¼Œä¸¦é€é **åŸå‹ ETF (1x)** çš„æ•¸æ“šä¾†ç”Ÿæˆè¨Šè™Ÿèˆ‡åˆæˆå›æ¸¬æ­·å²ï¼Œä»¥è§£æ±ºæ§“æ¡¿ ETF æ­·å²æ•¸æ“šéçŸ­çš„å•é¡Œã€‚
    
    | è§’è‰² | äº¤æ˜“ä»£è™Ÿ (3x) | è¨Šè™Ÿæºä»£è™Ÿ (1x) | å°æ‡‰è³‡ç”¢é¡åˆ¥ |
    | :--- | :--- | :--- | :--- |
    | **é€²æ”» (Risky)** | **UPRO** | SPY | ç¾è‚¡å¤§å‹è‚¡ (S&P 500) |
    | **é€²æ”» (Risky)** | **EURL** | VGK | æ­æ´²å·²é–‹ç™¼å¸‚å ´ |
    | **é€²æ”» (Risky)** | **EDC** | EEM | æ–°èˆˆå¸‚å ´ |
    | **é¿éšª (Safe)** | **GLD** / **TLT** | (è‡ªèº«) | é»ƒé‡‘ / 20å¹´æœŸç¾å‚µ |
    
    ### 2. é€²æ”»è³‡ç”¢é¸æ“‡æ©Ÿåˆ¶ (Selection Logic)
    ç­–ç•¥æ¯æœˆé€²è¡Œä¸€æ¬¡é¸è‚¡ï¼ŒæŒ‘é¸ç•¶ä¸‹å‹•èƒ½æœ€å¼·çš„ **1 æª”** é€²æ”»è³‡ç”¢ã€‚
    * **é »ç‡**ï¼šæœˆé »ï¼ˆMonthlyï¼‰ï¼Œæ–¼æ¯å€‹æœˆæœ€å¾Œä¸€å€‹äº¤æ˜“æ—¥è¨ˆç®—ã€‚
    * **å‹•èƒ½æŒ‡æ¨™**ï¼šç¶œåˆé¢¨éšªèª¿æ•´å‹•èƒ½ Z-Score (Composite Risk-Adjusted Momentum Z-Score)ã€‚
    * **è¨ˆç®—æ­¥é©Ÿ**ï¼š
        1. **å¤šé€±æœŸå›å ±**ï¼šè¨ˆç®— 3ã€6ã€9ã€12 å€‹æœˆçš„ç´¯ç©å ±é…¬ç‡ã€‚
        2. **æ³¢å‹•ç‡èª¿æ•´**ï¼šå°‡ä¸Šè¿°å ±é…¬ç‡é™¤ä»¥éå» 126 å¤©ï¼ˆç´„åŠå¹´ï¼‰çš„å¹´åŒ–æ³¢å‹•ç‡ï¼Œå¾—åˆ° Sharpe-like ratioã€‚
        3. **æ¨™æº–åŒ– (Z-Score)**ï¼šå°‡ä¸‰å€‹æ¨™çš„åœ¨åŒä¸€é€±æœŸå…§çš„æ•¸å€¼é€²è¡Œæ¨™æº–åŒ–ï¼ˆZ-Scoreï¼‰ã€‚
        4. **åŠ ç¸½è©•åˆ†**ï¼šå°‡å››å€‹é€±æœŸ (3/6/9/12M) çš„ Z-Score ç›¸åŠ ï¼Œç¸½åˆ†æœ€é«˜è€…å‹å‡ºã€‚
    
    ### 3. é›™å±¤å‹•æ…‹é¢¨æ§æ©Ÿåˆ¶ (Risk Control Logic)
    é¸å®šæ¨™çš„å¾Œï¼Œé€éå…©å±¤é¢¨æ§æ±ºå®šæ›éšªæ¯”ä¾‹ï¼ˆWeightï¼‰ã€‚æ¯å±¤é¢¨æ§è²¢ç» 50% æ¬Šé‡ï¼Œå› æ­¤æŒå€‰æ°´ä½å¯èƒ½ç‚º **0% (å…¨é¿éšª)ã€50% (åŠå€‰)ã€100% (å…¨æ”»)**ã€‚
    
    **ç¬¬ä¸€å±¤ï¼šè¶¨å‹¢æ¿¾ç¶² (Trend Filter) - æ¬Šé‡ 50%**
    * **æŒ‡æ¨™**ï¼š6 å€‹æœˆç°¡å–®ç§»å‹•å¹³å‡ç·š (SMA 6 Months)ã€‚
    * **é‚è¼¯**ï¼š
        * è‹¥ **æœˆæ”¶ç›¤åƒ¹ > 6å€‹æœˆå‡ç·š** $\rightarrow$ **SMA_State = 1 (å®‰å…¨)**ã€‚
        * è‹¥ **æœˆæ”¶ç›¤åƒ¹ < 6å€‹æœˆå‡ç·š** $\rightarrow$ **SMA_State = 0 (å±éšª)**ã€‚
    * **æ•¸æ“šæº**ï¼šä½¿ç”¨åŸå‹ ETF (å¦‚ SPY) åˆ¤æ–·ã€‚
    
    **ç¬¬äºŒå±¤ï¼šæ³¢å‹•ç‡æ¿¾ç¶² (Volatility Filter) - æ¬Šé‡ 50%**
    * **æ¨¡å‹**ï¼šGARCH(1,1) with Student's t-distributionã€‚
    * **è¨“ç·´çª—å£**ï¼š
        * **Live**ï¼šæœ€è¿‘ 504 å¤©ã€‚
        * **Backtest**ï¼šåš´æ ¼æ»¾å‹•è¦–çª—ï¼ˆRolling Windowï¼‰ï¼Œåªçœ‹éå» 504 å¤©ï¼Œçµ•ä¸ä½¿ç”¨æœªä¾†æ•¸æ“šã€‚
    * **é‡è¨“é »ç‡ (Refit)**ï¼šæ¯ 5 å¤©é‡æ–°æ“¬åˆä¸€æ¬¡ GARCH åƒæ•¸ã€‚
    * **è¨Šè™Ÿé‚è¼¯ (Regime Switching)**ï¼š
        1. é æ¸¬ T æ—¥çš„æ¢ä»¶æ³¢å‹•ç‡ (Conditional Volatility)ã€‚
        2. è¨ˆç®—è©²æ³¢å‹•ç‡åœ¨éå» 252 å¤©æ­·å²ä¸­çš„ **ç™¾åˆ†ä½æ•¸ (Quantile/Percentile)**ã€‚
        3. **å‡ºå ´ (Exit)**ï¼šè‹¥æ³¢å‹•ç‡ > æ­·å² **99%** åˆ†ä½æ•¸ $\rightarrow$ **GARCH_State = 0 (å±éšª)**ã€‚
        4. **é€²å ´ (Entry)**ï¼šè‹¥æ³¢å‹•ç‡ < æ­·å² **90%** åˆ†ä½æ•¸ $\rightarrow$ **GARCH_State = 1 (å®‰å…¨)**ã€‚
        5. **æ»¯å¾Œæ€§**ï¼šå…·å‚™ Hysteresis ç‰¹æ€§ï¼Œæœªè§¸ç™¼é–¾å€¼å‰ç¶­æŒåŸç‹€æ…‹ã€‚
    
    ### 4. é¿éšªè³‡ç”¢è¼ªå‹• (Safe Asset Rotation)
    ç•¶é€²æ”»è³‡ç”¢æ¬Šé‡æœªæ»¿ 100% æ™‚ï¼Œå‰©é¤˜è³‡é‡‘é…ç½®æ–¼é¿éšªè³‡ç”¢ã€‚
    * **å€™é¸æ± **ï¼šGLD (é»ƒé‡‘), TLT (ç¾å‚µ)ã€‚
    * **é¸æ“‡é‚è¼¯**ï¼šæ¯”è¼ƒå…©è€… **éå» 12 å€‹æœˆ** çš„ç´¯ç©å ±é…¬ç‡ï¼Œå¼·è€…å‹å‡ºã€‚
    * **é è¨­å€¼**ï¼šè‹¥æ•¸æ“šä¸è¶³ï¼Œé è¨­æŒæœ‰ TLTã€‚
    
    ### 5. åš´æ ¼å›æ¸¬ç´°ç¯€ (Strict Backtest Specifics)
    é€™éƒ¨åˆ†ç¨‹å¼ç¢¼éå¸¸å¼·èª¿ã€ŒçœŸå¯¦æ€§ã€èˆ‡ã€Œé˜²åèª¤ã€ï¼Œå…·é«”å¯¦ä½œå¦‚ä¸‹ï¼š
    
    **åˆæˆæ•¸æ“š (Synthetic Data)**ï¼š
    * ä¸ç›´æ¥ä½¿ç”¨ 3x ETF æ­·å²æ•¸æ“šï¼ˆå› æ™‚é–“å¤ªçŸ­ï¼‰ã€‚
    * **åˆæˆå…¬å¼**ï¼š$Ret_{3x} = (Ret_{1x} \times 3.0) - Cost_{borrow}$ã€‚
    * **èè³‡æˆæœ¬ ($Cost_{borrow}$)**ï¼šå‹•æ…‹è¨­å®šã€‚
        * 2008-2021 (ä½åˆ©æ™‚æœŸ)ï¼šå¹´åŒ– 2%ã€‚
        * 2022-è‡³ä»Š (å‡æ¯æ™‚æœŸ) æˆ– 2007ä»¥å‰ï¼šå¹´åŒ– 5%ã€‚
    
    **ç„¡å‰è¦–åå·® (Look-Ahead Bias Free)**ï¼š
    * GARCH æ¨¡å‹è¨“ç·´åš´æ ¼é™åˆ¶åœ¨ **t-504** åˆ° **t-1** çš„è¦–çª—å…§ã€‚
    * SMA èˆ‡å‹•èƒ½è¨Šè™Ÿå‡ä½¿ç”¨ T-1 æ—¥æˆ–ä¸Šå€‹æœˆåº•çš„æ•¸æ“šã€‚
    
    **äº¤æ˜“åŸ·è¡Œç´°ç¯€**ï¼š
    * **T+1 åŸ·è¡Œ**ï¼šT æ—¥è¨ˆç®—å‡ºçš„è¨Šè™Ÿï¼Œæ–¼ T+1 æ—¥é–‹ç›¤/æ”¶ç›¤åƒ¹åŸ·è¡Œï¼ˆç¨‹å¼ç¢¼é‚è¼¯ç‚ºæ—¥å ±é…¬çµç®—ï¼Œéš±å« T+1 æ¦‚å¿µï¼‰ã€‚
    * **äº¤æ˜“æˆæœ¬**ï¼šå–®é‚Š **0.1% (10 bps)**ã€‚
    * **ç„¡é¢¨éšªåˆ©ç‡ (Risk-Free Rate)**ï¼šè¨ˆç®— Sharpe Ratio æ™‚ä½¿ç”¨å¹´åŒ– 2%ã€‚
    
    ### 6. è¼¸å‡ºæŒ‡æ¨™ (Dashboard Metrics)
    å„€è¡¨æ¿æœ€çµ‚è¨ˆç®—ä¸¦å±•ç¤ºä»¥ä¸‹é—œéµç¸¾æ•ˆæŒ‡æ¨™ï¼š
    * **CAGR**ï¼šå¹´åŒ–è¤‡åˆæˆé•·ç‡ã€‚
    * **Sharpe Ratio**ï¼šå¤æ™®æ¯”ç‡ (è¶…é¡å ±é…¬ / æ¨™æº–å·®)ã€‚
    * **Sortino Ratio**ï¼šç´¢æè«¾æ¯”ç‡ (åªè€ƒæ…®ä¸‹è¡Œæ³¢å‹•)ã€‚
    * **Max Drawdown**ï¼šæœ€å¤§å›æ’¤ã€‚
    * **Avg Roll 5Y**ï¼šæ»¾å‹• 5 å¹´å¹³å‡å¹´åŒ–å ±é…¬ç‡ï¼ˆè©•ä¼°é•·æœŸæŒæœ‰ç©©å®šæ€§ï¼‰ã€‚
    * **Time in 3x**ï¼šæŒæœ‰ 3x æ§“æ¡¿è³‡ç”¢çš„æ™‚é–“æ¯”ä¾‹ã€‚
    
    **ç¸½çµï¼šç­–ç•¥æ ¸å¿ƒå…¬å¼**
    
    $$Weight_{Risky} = 0.5 \times I(Price > SMA_{6m}) + 0.5 \times I(Vol_{GARCH} < Threshold)$$
    
    $$Position = Weight_{Risky} \times \text{Best\_Momentum\_3x} + (1 - Weight_{Risky}) \times \text{Best\_Safe\_Asset}$$
    
    é€™æ˜¯ä¸€å€‹çµåˆäº† **ã€Œç›¸å°å‹•èƒ½ (é¸è‚¡)ã€** èˆ‡ **ã€Œé›™é‡çµ•å°å‹•èƒ½ (æ“‡æ™‚)ã€** çš„è¤‡åˆç­–ç•¥ã€‚
    """)

c1, c2, c3, c4 = st.columns(4)
with c1: st.metric("ğŸ† æœ¬æœˆé€²æ”»è´å®¶", winner)
with c2: 
    color = "green" if final_w==1 else "orange" if final_w==0.5 else "red"
    st.markdown(f"### ğŸ¯ æ¬Šé‡: :{color}[{final_w*100:.0f}%]")
with c3: 
    st.metric("GARCH é¢¨æ§", "å®‰å…¨" if g_state==1 else "å±éšª", delta="âœ…" if g_state==1 else "ğŸ”»")
with c4: 
    s_val = safe_df.loc[safe_win, '12M Return'] if not safe_df.empty else 0
    st.metric("ğŸ›¡ï¸ é¿éšªè³‡ç”¢", safe_win, f"12M: {s_val:.1%}")

st.divider()

t1, t2, t3, t4, t5, t6 = st.tabs(["æ•¸æ“š", "é¢¨æ§ç´°ç¯€", "æ¬Šé‡ç‹€æ…‹", "é¸è‚¡æ’å", "é¿éšªè¼ªå‹•", "éƒ¨ä½ç¸½çµ"])
with t1: st.dataframe(live_data.tail(5).style.format("{:.2f}"), use_container_width=True)
with t2:
    if winner in risk_live:
        st.dataframe(risk_live[winner].tail(10)[['Price','Vol','Exit_Th','Entry_Th','GARCH_State']].style.format("{:.2f}"), use_container_width=True)
with t3:
    if winner in risk_live:
        st.dataframe(risk_live[winner].tail(10)[['GARCH_State','SMA_State','Weight']], use_container_width=True)
with t4: st.dataframe(sel_df.style.format("{:.2f}"), use_container_width=True)
with t5: st.dataframe(safe_df.style.format("{:.2%}"), use_container_width=True)
with t6: st.success(f"å»ºè­°æŒæœ‰: **{final_w*100:.0f}% {winner}** + **{(1-final_w)*100:.0f}% {safe_win}**")

st.divider()

# ==========================================
# 5. å›æ¸¬å€å¡Š (Strict Rolling)
# ==========================================
st.header("â³ åš´æ ¼æ»¾å‹•å›æ¸¬ (Synthetic 3x)")
st.caption("å›æ¸¬æ•¸æ“šä½¿ç”¨ 1x åŸå‹ ETF åˆæˆï¼Œä¸¦è‡ªå‹•å°é½Š VT ä¸Šå¸‚æ—¥ä»¥ç¢ºä¿åŸºæº–ä¸€è‡´ã€‚")

syn_data = get_synthetic_backtest_data()

if not syn_data.empty:
    if st.button("ğŸš€ é–‹å§‹æ»¾å‹•å›æ¸¬ (ç´„éœ€ 30-60 ç§’)"):
        with st.spinner("æ­£åœ¨é€²è¡Œ GARCH æ»¾å‹•è¨“ç·´èˆ‡åƒæ•¸æ“¬åˆ..."):
            h_risk, h_win, h_safe = calculate_backtest_signals_rolling(syn_data)
            
        with st.spinner("æ­£åœ¨åŸ·è¡Œäº¤æ˜“å›æ¸¬..."):
            s_eq, b_eq, v_eq, holds = run_backtest_logic(syn_data, h_risk, h_win, h_safe)
        
        if s_eq is not None:
            # Stats
            def calc_stats(eq, dr):
                d = (eq.index[-1] - eq.index[0]).days
                cagr = (eq.iloc[-1]) ** (365.25/d) - 1
                mdd = (eq / eq.cummax() - 1).min()
                excess = dr - (RF_RATE/252)
                sharpe = (excess.mean()/excess.std())*np.sqrt(252)
                down = excess.copy(); down[down>0]=0
                down_std = np.sqrt((down**2).mean())*np.sqrt(252)
                sortino = (excess.mean()*252)/(down_std+1e-6)
                return cagr, sortino, sharpe, mdd
            
            s_s = calc_stats(s_eq, s_eq.pct_change().fillna(0))
            b_s = calc_stats(b_eq, b_eq.pct_change().fillna(0))
            v_s = calc_stats(v_eq, v_eq.pct_change().fillna(0))
            
            r5_s = s_eq.rolling(1260).apply(lambda x: (x.iloc[-1]/x.iloc[0])**(252/1260)-1).mean()
            r5_b = b_eq.rolling(1260).apply(lambda x: (x.iloc[-1]/x.iloc[0])**(252/1260)-1).mean()
            r5_v = v_eq.rolling(1260).apply(lambda x: (x.iloc[-1]/x.iloc[0])**(252/1260)-1).mean()

            st.write("### ğŸ“ˆ ç¸¾æ•ˆæŒ‡æ¨™")
            m1, m2, m3, m4, m5, m6 = st.columns(6)
            
            def m_box(label, v, b, vt, fmt="{:.2%}"):
                st.markdown(f"""
                <div class="metric-card">
                    <p class="metric-label">{label}</p>
                    <p class="metric-value">{fmt.format(v)}</p>
                    <p class="metric-sub">3x: {fmt.format(b)} | VT: {fmt.format(vt)}</p>
                </div>""", unsafe_allow_html=True)
                
            with m1: m_box("CAGR", s_s[0], b_s[0], v_s[0])
            with m2: m_box("Sortino", s_s[1], b_s[1], v_s[1], "{:.2f}")
            with m3: m_box("Sharpe", s_s[2], b_s[2], v_s[2], "{:.2f}")
            with m4: m_box("Avg 5Y", r5_s, r5_b, r5_v)
            with m5: m_box("MaxDD", s_s[3], b_s[3], v_s[3])
            
            # [FIX] Time in 3x ä¿®æ­£é‚è¼¯
            # holds çš„ key æ˜¯ 3x ticker åç¨± (e.g. UPRO, EURL)ï¼Œæª¢æŸ¥ key æ˜¯å¦åœ¨ MAPPING ä¸­
            risky_hold_sum = sum([v for k,v in holds.items() if k in MAPPING.keys()])
            t_3x = risky_hold_sum / len(s_eq)
            with m6: m_box("Time in 3x", t_3x, 1.0, 1.0)
            
            st.divider()
            
            # --- Charting (Fixing Altair Display) ---
            st.write("### ğŸ“Š æ¬Šç›Šæ›²ç·š")
            df_chart = pd.DataFrame({'Date': s_eq.index, 'Strategy': s_eq, 'Bench (3x)': b_eq, 'VT': v_eq}).melt('Date', var_name='Asset', value_name='NAV')
            c1 = alt.Chart(df_chart).mark_line().encode(
                x='Date', y=alt.Y('NAV', scale=alt.Scale(type='log')), 
                color='Asset', tooltip=['Date','Asset', alt.Tooltip('NAV', format='.2f')]
            ).properties(width=800, height=350)
            st.altair_chart(c1, use_container_width=True)

            c_col1, c_col2 = st.columns(2)
            with c_col1:
                st.write("### ğŸ“‰ å›æ’¤å¹…åº¦")
                dd_s = s_eq/s_eq.cummax()-1
                dd_b = b_eq/b_eq.cummax()-1
                dd_v = v_eq/v_eq.cummax()-1
                df_dd = pd.DataFrame({'Date': s_eq.index, 'Strategy': dd_s, 'Bench (3x)': dd_b, 'VT': dd_v}).melt('Date', var_name='Asset', value_name='DD')
                c2 = alt.Chart(df_dd).mark_line().encode(
                    x='Date', y=alt.Y('DD', axis=alt.Axis(format='%')), 
                    color='Asset', tooltip=['Date','Asset', alt.Tooltip('DD', format='.2%')]
                ).properties(width=400, height=250)
                st.altair_chart(c2, use_container_width=True)
            
            with c_col2:
                st.write("### ğŸ”„ æ»¾å‹• 5 å¹´å¹´åŒ–")
                roll_s = s_eq.rolling(1260).apply(lambda x: (x.iloc[-1]/x.iloc[0])**(252/1260)-1)
                roll_b = b_eq.rolling(1260).apply(lambda x: (x.iloc[-1]/x.iloc[0])**(252/1260)-1)
                roll_v = v_eq.rolling(1260).apply(lambda x: (x.iloc[-1]/x.iloc[0])**(252/1260)-1)
                df_r5 = pd.DataFrame({'Date': s_eq.index, 'Strategy': roll_s, 'Bench (3x)': roll_b, 'VT': roll_v}).melt('Date', var_name='Asset', value_name='Roll5Y')
                c3 = alt.Chart(df_r5.dropna()).mark_line().encode(
                    x='Date', y=alt.Y('Roll5Y', axis=alt.Axis(format='%')), 
                    color='Asset', tooltip=['Date','Asset', alt.Tooltip('Roll5Y', format='.2%')]
                ).properties(width=400, height=250)
                st.altair_chart(c3, use_container_width=True)
